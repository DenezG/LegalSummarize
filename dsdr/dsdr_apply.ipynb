{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "212587f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/ailyhotte/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dsdr import DSDR\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c629a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json('../data/easy/train.json')\n",
    "test = data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d00cf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the elements in the 'written_opinion' list into a single string\n",
    "text = ''\n",
    "for key, value in test['written_opinion']['parsed'].items():\n",
    "    text += value\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1111d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "V = vectorizer.fit_transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfda10d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences:\n",
      "- See App.\n",
      "- Stumpf argues that his plea was so inconsistent with his denial of having shot Mrs. Stout that he could only have pleaded guilty out of ignorance of the aggravated murder charge’s specific intent element.\n",
      "- 04-637 MARGARET BRADSHAW, WARDEN, PETITIONER v. JOHN DAVID STUMPF on writ of certiorari to the united states court of appeals for the sixth circuit [June 13, 2005] Justice O’Connor delivered the opinion of the Court.\n",
      "- for Cert.\n",
      "- to Pet.\n",
      "- The State, however, claimed that Stumpf had shot Mrs. Stout, and that he therefore was the principal offender in her murder.\n",
      "- After Wesley’s trial, Stumpf moved to withdraw his own plea or vacate his death sentence, arguing that the evidence endorsed by the State in Wesley’s trial cast doubt on Stumpf ’s conviction and sentence.\n",
      "- While a guilty plea is invalid if the defendant has not been informed of the crime’s elements, Stumpf ’s attorneys represented at his plea hearing that they had explained the elements to their client, and Stumpf confirmed that the representation was true.\n",
      "- Moreover, I agree with the Court that “Stumpf has never provided an explanation of how the prosecution’s postplea use of inconsistent arguments could have affected the knowing, voluntary, and intelligent nature of his plea.” Ante, at 11.\n",
      "- It is not clear whether the Court of Appeals would have concluded that Stumpf was entitled to resentencing had the court not also considered the conviction invalid.\n"
     ]
    }
   ],
   "source": [
    "summary_indices = DSDR.lin(V, m=10, lamb=0.1)\n",
    "print(\"Summary sentences:\")\n",
    "summary = ''\n",
    "for i in summary_indices:\n",
    "    print(\"-\", sentences[i])\n",
    "    summary += sentences[i] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0e8fa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ROUGE : {'rouge1': 0.4812834224598931, 'rouge2': 0.17741935483870966, 'rougeL': 0.21925133689839574}\n"
     ]
    }
   ],
   "source": [
    "def calculate_rouge(prediction, reference):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    return {k: v.fmeasure for k, v in scores.items()}\n",
    "\n",
    "rouge_score = calculate_rouge(summary, test['Summary']['conclusion'])\n",
    "print(\"Score ROUGE :\", rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "402f6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsdr_rouge(index):\n",
    "    data = pd.read_json('../data/easy/train.json')\n",
    "    row = data.iloc[index]\n",
    "    \n",
    "    #concatenate all the elements in the 'written_opinion' list into a single string\n",
    "    text = ''\n",
    "    for key, value in row['written_opinion']['parsed'].items():\n",
    "        text += value\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    V = vectorizer.fit_transform(sentences).toarray()\n",
    "    \n",
    "    summary_indices = DSDR.lin(V, m=10, lamb=0.1)\n",
    "    summary = ''\n",
    "    for i in summary_indices:\n",
    "        summary += sentences[i] + ' '\n",
    "    \n",
    "    rouge_score = calculate_rouge(summary, test['Summary']['conclusion'])\n",
    "    return rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5b2026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 documents\n",
      "Processed 10 documents\n",
      "Processed 20 documents\n",
      "Processed 30 documents\n",
      "Processed 40 documents\n",
      "Processed 50 documents\n",
      "Processed 60 documents\n",
      "Processed 70 documents\n",
      "Processed 80 documents\n",
      "Processed 90 documents\n",
      "Average ROUGE scores over the dataset:\n",
      "{'rouge1': 0.028355263670596768, 'rouge2': 0.0025879263529449514, 'rougeL': 0.015979388712446682}\n"
     ]
    }
   ],
   "source": [
    "res = {\n",
    "    'rouge1': 0,\n",
    "    'rouge2': 0,\n",
    "    'rougeL': 0\n",
    "}\n",
    "for i in range(100):\n",
    "    score = dsdr_rouge(i)\n",
    "    res['rouge1'] += score['rouge1']\n",
    "    res['rouge2'] += score['rouge2']\n",
    "    res['rougeL'] += score['rougeL']\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {i} documents\")\n",
    "print(\"Average ROUGE scores over the dataset:\")\n",
    "print({k: v / len(data) for k, v in res.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cff0f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.24101974120007252, 'rouge2': 0.021997374000032086, 'rougeL': 0.13582480405579678}\n"
     ]
    }
   ],
   "source": [
    "print({k: v / 100 for k, v in res.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58950a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.24832214765100674,\n",
       " 'rouge2': 0.02027027027027027,\n",
       " 'rougeL': 0.14093959731543623}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsdr_rouge(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87ea61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
